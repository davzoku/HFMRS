{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324bfccc-4ba6-4f57-abea-35a44706d8e7",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a78c915-285a-4afb-888f-c203425acf1d",
   "metadata": {},
   "source": [
    "## Jaccard Similarity\n",
    "\n",
    "[Calculate Jaccard Similarity in Python - Data Science Parichay](https://datascienceparichay.com/article/jaccard-similarity-python/)\n",
    "\n",
    "TLDR: \n",
    "Jaccard Similarity is find the count of overlapping rows over total number of rows\n",
    "\n",
    "[Clear Example of Jaccard Similarity // Visual Explanation of What is the Jaccard Index? - YouTube](https://www.youtube.com/watch?v=YotbvhndSf4)\n",
    "\n",
    "\n",
    "![image-4.png.webp (273×92)](https://datascienceparichay.com/wp-content/uploads/2021/11/image-4.png.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f636d1b2-354a-4b08-8232-d61df1567434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a9376c-7b98-4dda-ad3f-97d9b8111a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelId</th>\n",
       "      <th>lastModified</th>\n",
       "      <th>tags</th>\n",
       "      <th>pipeline_tag</th>\n",
       "      <th>author</th>\n",
       "      <th>architectures</th>\n",
       "      <th>model_type</th>\n",
       "      <th>datasets</th>\n",
       "      <th>downloads</th>\n",
       "      <th>library_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jonatasgrosman/wav2vec2-large-xlsr-53-english</td>\n",
       "      <td>2023-03-25T10:56:55.000Z</td>\n",
       "      <td>['pytorch', 'jax', 'safetensors', 'wav2vec2', ...</td>\n",
       "      <td>automatic-speech-recognition</td>\n",
       "      <td>jonatasgrosman</td>\n",
       "      <td>['Wav2Vec2ForCTC']</td>\n",
       "      <td>wav2vec2</td>\n",
       "      <td>['common_voice', 'mozilla-foundation/common_vo...</td>\n",
       "      <td>47102358</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>2022-11-16T15:15:39.000Z</td>\n",
       "      <td>['pytorch', 'tf', 'jax', 'rust', 'safetensors'...</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['BertForMaskedLM']</td>\n",
       "      <td>bert</td>\n",
       "      <td>['bookcorpus', 'wikipedia']</td>\n",
       "      <td>46484719</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Davlan/distilbert-base-multilingual-cased-ner-hrl</td>\n",
       "      <td>2022-06-27T10:49:50.000Z</td>\n",
       "      <td>['pytorch', 'tf', 'distilbert', 'token-classif...</td>\n",
       "      <td>token-classification</td>\n",
       "      <td>Davlan</td>\n",
       "      <td>['DistilBertForTokenClassification']</td>\n",
       "      <td>distilbert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29407063</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>2022-12-16T15:44:21.000Z</td>\n",
       "      <td>['pytorch', 'tf', 'jax', 'tflite', 'rust', 'sa...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['GPT2LMHeadModel']</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21999611</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>2023-04-07T12:46:17.000Z</td>\n",
       "      <td>['pytorch', 'tf', 'jax', 'onnx', 'safetensors'...</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['XLMRobertaForMaskedLM']</td>\n",
       "      <td>xlm-roberta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20333162</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             modelId  \\\n",
       "0      jonatasgrosman/wav2vec2-large-xlsr-53-english   \n",
       "1                                  bert-base-uncased   \n",
       "2  Davlan/distilbert-base-multilingual-cased-ner-hrl   \n",
       "3                                               gpt2   \n",
       "4                                   xlm-roberta-base   \n",
       "\n",
       "               lastModified  \\\n",
       "0  2023-03-25T10:56:55.000Z   \n",
       "1  2022-11-16T15:15:39.000Z   \n",
       "2  2022-06-27T10:49:50.000Z   \n",
       "3  2022-12-16T15:44:21.000Z   \n",
       "4  2023-04-07T12:46:17.000Z   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['pytorch', 'jax', 'safetensors', 'wav2vec2', ...   \n",
       "1  ['pytorch', 'tf', 'jax', 'rust', 'safetensors'...   \n",
       "2  ['pytorch', 'tf', 'distilbert', 'token-classif...   \n",
       "3  ['pytorch', 'tf', 'jax', 'tflite', 'rust', 'sa...   \n",
       "4  ['pytorch', 'tf', 'jax', 'onnx', 'safetensors'...   \n",
       "\n",
       "                   pipeline_tag          author  \\\n",
       "0  automatic-speech-recognition  jonatasgrosman   \n",
       "1                     fill-mask             NaN   \n",
       "2          token-classification          Davlan   \n",
       "3               text-generation             NaN   \n",
       "4                     fill-mask             NaN   \n",
       "\n",
       "                          architectures   model_type  \\\n",
       "0                    ['Wav2Vec2ForCTC']     wav2vec2   \n",
       "1                   ['BertForMaskedLM']         bert   \n",
       "2  ['DistilBertForTokenClassification']   distilbert   \n",
       "3                   ['GPT2LMHeadModel']         gpt2   \n",
       "4             ['XLMRobertaForMaskedLM']  xlm-roberta   \n",
       "\n",
       "                                            datasets  downloads  library_name  \n",
       "0  ['common_voice', 'mozilla-foundation/common_vo...   47102358  transformers  \n",
       "1                        ['bookcorpus', 'wikipedia']   46484719  transformers  \n",
       "2                                                NaN   29407063  transformers  \n",
       "3                                                NaN   21999611  transformers  \n",
       "4                                                NaN   20333162  transformers  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f64a6e-2ff7-4848-a17c-5e72bf83f0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['modelId', 'lastModified', 'tags', 'pipeline_tag', 'author',\n",
       "       'architectures', 'model_type', 'datasets', 'downloads', 'library_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12a164f-520c-4c06-9ef6-be8dc093bd7e",
   "metadata": {},
   "source": [
    "Model with minimal columns for POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91c87d6c-08d0-4c0a-b4c9-d23707237366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mini = df[['modelId', 'pipeline_tag', 'architectures', 'model_type', 'library_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07dc765f-cfa1-442b-8eb1-9070cea8f093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pipeline_tag', 'architectures', 'model_type', 'library_name'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Select feature columns\n",
    "feature_cols = df_mini.columns[1:]\n",
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "796b3fba-a51d-4de2-8178-6c488f6bc502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pn/qz12b_x55lx3hjqmrpty0b_00000gn/T/ipykernel_77584/879861508.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mini['architectures'] = df_mini['architectures'].apply(lambda x: str(x).strip('[]'))\n"
     ]
    }
   ],
   "source": [
    "# minimal cleaning\n",
    "df_mini['architectures'] = df_mini['architectures'].apply(lambda x: str(x).strip('[]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50caa15e-8592-48c8-8a69-e40fd06dcc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pipeline_tag_audio-classification', 'pipeline_tag_audio-to-audio',\n",
      "       'pipeline_tag_automatic-speech-recognition',\n",
      "       'pipeline_tag_conversational', 'pipeline_tag_depth-estimation',\n",
      "       'pipeline_tag_document-question-answering',\n",
      "       'pipeline_tag_feature-extraction', 'pipeline_tag_fill-mask',\n",
      "       'pipeline_tag_graph-ml', 'pipeline_tag_image-classification',\n",
      "       ...\n",
      "       'library_name_span_marker', 'library_name_speechbrain',\n",
      "       'library_name_stable-baselines3', 'library_name_stable-diffusion',\n",
      "       'library_name_stanza', 'library_name_timm', 'library_name_transformers',\n",
      "       'library_name_txtai', 'library_name_ultralytics',\n",
      "       'library_name_yolov5'],\n",
      "      dtype='object', length=1007)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode columns 1 to end\n",
    "df_one_hot = pd.get_dummies(df_mini.iloc[:, 1:])\n",
    "\n",
    "print(df_one_hot.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa78a7f1-ab2a-48f4-aec7-64a462514a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the encoded DataFrame with the modelId column\n",
    "df_one_hot = pd.concat([df_mini['modelId'], df_one_hot], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5bb3141-467c-4caf-a79a-c4fe055574bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelId</th>\n",
       "      <th>pipeline_tag_audio-classification</th>\n",
       "      <th>pipeline_tag_audio-to-audio</th>\n",
       "      <th>pipeline_tag_automatic-speech-recognition</th>\n",
       "      <th>pipeline_tag_conversational</th>\n",
       "      <th>pipeline_tag_depth-estimation</th>\n",
       "      <th>pipeline_tag_document-question-answering</th>\n",
       "      <th>pipeline_tag_feature-extraction</th>\n",
       "      <th>pipeline_tag_fill-mask</th>\n",
       "      <th>pipeline_tag_graph-ml</th>\n",
       "      <th>...</th>\n",
       "      <th>library_name_span_marker</th>\n",
       "      <th>library_name_speechbrain</th>\n",
       "      <th>library_name_stable-baselines3</th>\n",
       "      <th>library_name_stable-diffusion</th>\n",
       "      <th>library_name_stanza</th>\n",
       "      <th>library_name_timm</th>\n",
       "      <th>library_name_transformers</th>\n",
       "      <th>library_name_txtai</th>\n",
       "      <th>library_name_ultralytics</th>\n",
       "      <th>library_name_yolov5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jonatasgrosman/wav2vec2-large-xlsr-53-english</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Davlan/distilbert-base-multilingual-cased-ner-hrl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             modelId  \\\n",
       "0      jonatasgrosman/wav2vec2-large-xlsr-53-english   \n",
       "1                                  bert-base-uncased   \n",
       "2  Davlan/distilbert-base-multilingual-cased-ner-hrl   \n",
       "3                                               gpt2   \n",
       "4                                   xlm-roberta-base   \n",
       "\n",
       "   pipeline_tag_audio-classification  pipeline_tag_audio-to-audio  \\\n",
       "0                                  0                            0   \n",
       "1                                  0                            0   \n",
       "2                                  0                            0   \n",
       "3                                  0                            0   \n",
       "4                                  0                            0   \n",
       "\n",
       "   pipeline_tag_automatic-speech-recognition  pipeline_tag_conversational  \\\n",
       "0                                          1                            0   \n",
       "1                                          0                            0   \n",
       "2                                          0                            0   \n",
       "3                                          0                            0   \n",
       "4                                          0                            0   \n",
       "\n",
       "   pipeline_tag_depth-estimation  pipeline_tag_document-question-answering  \\\n",
       "0                              0                                         0   \n",
       "1                              0                                         0   \n",
       "2                              0                                         0   \n",
       "3                              0                                         0   \n",
       "4                              0                                         0   \n",
       "\n",
       "   pipeline_tag_feature-extraction  pipeline_tag_fill-mask  \\\n",
       "0                                0                       0   \n",
       "1                                0                       1   \n",
       "2                                0                       0   \n",
       "3                                0                       0   \n",
       "4                                0                       1   \n",
       "\n",
       "   pipeline_tag_graph-ml  ...  library_name_span_marker  \\\n",
       "0                      0  ...                         0   \n",
       "1                      0  ...                         0   \n",
       "2                      0  ...                         0   \n",
       "3                      0  ...                         0   \n",
       "4                      0  ...                         0   \n",
       "\n",
       "   library_name_speechbrain  library_name_stable-baselines3  \\\n",
       "0                         0                               0   \n",
       "1                         0                               0   \n",
       "2                         0                               0   \n",
       "3                         0                               0   \n",
       "4                         0                               0   \n",
       "\n",
       "   library_name_stable-diffusion  library_name_stanza  library_name_timm  \\\n",
       "0                              0                    0                  0   \n",
       "1                              0                    0                  0   \n",
       "2                              0                    0                  0   \n",
       "3                              0                    0                  0   \n",
       "4                              0                    0                  0   \n",
       "\n",
       "   library_name_transformers  library_name_txtai  library_name_ultralytics  \\\n",
       "0                          1                   0                         0   \n",
       "1                          1                   0                         0   \n",
       "2                          1                   0                         0   \n",
       "3                          1                   0                         0   \n",
       "4                          1                   0                         0   \n",
       "\n",
       "   library_name_yolov5  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "\n",
       "[5 rows x 1008 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa27d659-b61e-4325-8d77-ba0dddfab598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/mini/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:2025: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Calculate pairwise Jaccard similarity\n",
    "similarity_matrix = 1 - pairwise_distances(df_one_hot.to_numpy(), metric='jaccard')\n",
    "print(similarity_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "529b5b9f-bb5d-45a7-a2e4-0891c6a2067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(df, similarity_matrix, modelId, recommend_no, method = \"jaccard\"):\n",
    "    if modelId in df['modelId'].values:\n",
    "        index = df[df['modelId'] == modelId].index[0]\n",
    "        print(f\"Find model of index {index}\")\n",
    "        \n",
    "    else:\n",
    "        print(f'Error: product_name \"{product_name}\" not found in dataframe.')\n",
    "    \n",
    "    if \"jaccard\" == method.lower():\n",
    "        similar_indices = similarity_matrix[index].argsort()[::-1][1:recommend_no+1]\n",
    "        similar_models = df.iloc[similar_indices]['modelId']\n",
    "        similarity_scores = similarity_matrix[index][similar_indices]\n",
    "        \n",
    "        print(f'Target Model: {df.iloc[index][\"modelId\"]}')\n",
    "        print(f'{recommend_no} Recommended Models:\\n{similar_models}')\n",
    "        print(f'Similarity Scores: {similarity_scores}')\n",
    "    \n",
    "    else:\n",
    "        print(f\"{method} not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3919656e-bc11-43a6-bb52-831a3b437a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find model of index 1\n",
      "Target Model: bert-base-uncased\n",
      "5 Recommended Models:\n",
      "4376                             asafaya/bert-mini-arabic\n",
      "9562    anon-submission-mk/bert-base-macedonian-bulgar...\n",
      "3610                     jcblaise/bert-tagalog-base-cased\n",
      "1292                                             hfl/rbt3\n",
      "5972             pierreguillou/bert-base-cased-pt-lenerbr\n",
      "Name: modelId, dtype: object\n",
      "Similarity Scores: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "get_recommendations(df_one_hot, similarity_matrix, \"bert-base-uncased\", 5, method=\"jaccard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5d8c82e-c85b-4dea-8e09-3f4bfa4b043b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelId</th>\n",
       "      <th>pipeline_tag</th>\n",
       "      <th>architectures</th>\n",
       "      <th>model_type</th>\n",
       "      <th>library_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>'BertForMaskedLM'</td>\n",
       "      <td>bert</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4376</th>\n",
       "      <td>asafaya/bert-mini-arabic</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>'BertForMaskedLM'</td>\n",
       "      <td>bert</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>anon-submission-mk/bert-base-macedonian-bulgar...</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>'BertForMaskedLM'</td>\n",
       "      <td>bert</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610</th>\n",
       "      <td>jcblaise/bert-tagalog-base-cased</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>'BertForMaskedLM'</td>\n",
       "      <td>bert</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                modelId pipeline_tag  \\\n",
       "1                                     bert-base-uncased    fill-mask   \n",
       "4376                           asafaya/bert-mini-arabic    fill-mask   \n",
       "9562  anon-submission-mk/bert-base-macedonian-bulgar...    fill-mask   \n",
       "3610                   jcblaise/bert-tagalog-base-cased    fill-mask   \n",
       "\n",
       "          architectures model_type  library_name  \n",
       "1     'BertForMaskedLM'       bert  transformers  \n",
       "4376  'BertForMaskedLM'       bert  transformers  \n",
       "9562  'BertForMaskedLM'       bert  transformers  \n",
       "3610  'BertForMaskedLM'       bert  transformers  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mini.iloc[[1,4376,9562, 3610]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76286bf-3017-4a20-8d40-004171021d2d",
   "metadata": {},
   "source": [
    "Note how the similarity score is just 1 for the top 5 records, essentially, the performance of this simple model is likely the same as doing a filtered search based on these parameters.\n",
    "\n",
    "This can serves as a simple baseline, and we may have to consider more features to yield more interesting results than a filtered search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20b6785b-d766-4e1e-934a-c898f98a012d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find model of index 4376\n",
      "Target Model: asafaya/bert-mini-arabic\n",
      "5 Recommended Models:\n",
      "4376                             asafaya/bert-mini-arabic\n",
      "9562    anon-submission-mk/bert-base-macedonian-bulgar...\n",
      "3610                     jcblaise/bert-tagalog-base-cased\n",
      "1292                                             hfl/rbt3\n",
      "5972             pierreguillou/bert-base-cased-pt-lenerbr\n",
      "Name: modelId, dtype: object\n",
      "Similarity Scores: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "get_recommendations(df_one_hot, similarity_matrix, \"asafaya/bert-mini-arabic\", 5, method=\"jaccard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53050af3-0999-4962-a897-26a313f4bb6a",
   "metadata": {},
   "source": [
    "When we chain the search eg. get_recommend for Model 1, method returns Model 2,3,4. get_recommend for 2 may not return Model 1. It is not cyclic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f0bba3-cceb-4612-9808-835dd1020ed5",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n",
    "\n",
    "![2b4a7a82-ad4c-4b2a-b808-e423a334de6f.png (488×376)](https://www.oreilly.com/api/v2/epubs/9781788295758/files/assets/2b4a7a82-ad4c-4b2a-b808-e423a334de6f.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "81c6cfda-338f-4bc5-8680-7a5e4c3f5697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e637264-1b4a-4c49-a7e6-48f7086f49bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/walter/code/aiap12/HFMRS/notebooks'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "729ed0e7-dbf3-45fd-8294-5042bbfe5f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:41:45 : INFO : Soup of words\n",
      "22:41:47 : INFO : Cleaned Data\n",
      "22:41:47 : INFO : Returning Pandas dataframe\n",
      "22:41:47 : INFO : Exported to csv file - /Users/walter/code/aiap12/HFMRS/data/processed/data.csv\n"
     ]
    }
   ],
   "source": [
    "input_path= \"../../data/raw/data.csv\"\n",
    "output_path = \"data/processed/data.csv\"\n",
    "\n",
    "preprocess_pipeline = preprocess.Preprocess(input_path = input_path, output_path = output_path, return_df=True)\n",
    "\n",
    "df_soup = preprocess_pipeline.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de1eb619-5370-4a4a-9505-58e8d01eb412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelId</th>\n",
       "      <th>tags</th>\n",
       "      <th>pipeline_tag</th>\n",
       "      <th>author</th>\n",
       "      <th>architectures</th>\n",
       "      <th>model_type</th>\n",
       "      <th>datasets</th>\n",
       "      <th>downloads</th>\n",
       "      <th>library_name</th>\n",
       "      <th>soup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jonatasgrosman/wav2vec2-large-xlsr-53-english</td>\n",
       "      <td>pytorch    jax    safetensors    wav2vec2   ...</td>\n",
       "      <td>automatic speech recognition</td>\n",
       "      <td>jonatasgrosman</td>\n",
       "      <td>wav2vec2forctc</td>\n",
       "      <td>wav2vec2</td>\n",
       "      <td>common voice    mozilla foundation common vo...</td>\n",
       "      <td>47102358</td>\n",
       "      <td>transformers</td>\n",
       "      <td>pytorch    jax    safetensors    wav2vec2   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>pytorch    tf    jax    rust    safetensors ...</td>\n",
       "      <td>fill mask</td>\n",
       "      <td>nan</td>\n",
       "      <td>bertformaskedlm</td>\n",
       "      <td>bert</td>\n",
       "      <td>bookcorpus    wikipedia</td>\n",
       "      <td>46484719</td>\n",
       "      <td>transformers</td>\n",
       "      <td>pytorch    tf    jax    rust    safetensors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Davlan/distilbert-base-multilingual-cased-ner-hrl</td>\n",
       "      <td>pytorch    tf    distilbert    token classif...</td>\n",
       "      <td>token classification</td>\n",
       "      <td>davlan</td>\n",
       "      <td>distilbertfortokenclassification</td>\n",
       "      <td>distilbert</td>\n",
       "      <td>nan</td>\n",
       "      <td>29407063</td>\n",
       "      <td>transformers</td>\n",
       "      <td>pytorch    tf    distilbert    token classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>pytorch    tf    jax    tflite    rust    sa...</td>\n",
       "      <td>text generation</td>\n",
       "      <td>nan</td>\n",
       "      <td>gpt2lmheadmodel</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>nan</td>\n",
       "      <td>21999611</td>\n",
       "      <td>transformers</td>\n",
       "      <td>pytorch    tf    jax    tflite    rust    sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>pytorch    tf    jax    onnx    safetensors ...</td>\n",
       "      <td>fill mask</td>\n",
       "      <td>nan</td>\n",
       "      <td>xlmrobertaformaskedlm</td>\n",
       "      <td>xlm roberta</td>\n",
       "      <td>nan</td>\n",
       "      <td>20333162</td>\n",
       "      <td>transformers</td>\n",
       "      <td>pytorch    tf    jax    onnx    safetensors ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             modelId  \\\n",
       "0      jonatasgrosman/wav2vec2-large-xlsr-53-english   \n",
       "1                                  bert-base-uncased   \n",
       "2  Davlan/distilbert-base-multilingual-cased-ner-hrl   \n",
       "3                                               gpt2   \n",
       "4                                   xlm-roberta-base   \n",
       "\n",
       "                                                tags  \\\n",
       "0    pytorch    jax    safetensors    wav2vec2   ...   \n",
       "1    pytorch    tf    jax    rust    safetensors ...   \n",
       "2    pytorch    tf    distilbert    token classif...   \n",
       "3    pytorch    tf    jax    tflite    rust    sa...   \n",
       "4    pytorch    tf    jax    onnx    safetensors ...   \n",
       "\n",
       "                   pipeline_tag          author  \\\n",
       "0  automatic speech recognition  jonatasgrosman   \n",
       "1                     fill mask             nan   \n",
       "2          token classification          davlan   \n",
       "3               text generation             nan   \n",
       "4                     fill mask             nan   \n",
       "\n",
       "                          architectures   model_type  \\\n",
       "0                      wav2vec2forctc       wav2vec2   \n",
       "1                     bertformaskedlm           bert   \n",
       "2    distilbertfortokenclassification     distilbert   \n",
       "3                     gpt2lmheadmodel           gpt2   \n",
       "4               xlmrobertaformaskedlm    xlm roberta   \n",
       "\n",
       "                                            datasets  downloads  library_name  \\\n",
       "0    common voice    mozilla foundation common vo...   47102358  transformers   \n",
       "1                          bookcorpus    wikipedia     46484719  transformers   \n",
       "2                                                nan   29407063  transformers   \n",
       "3                                                nan   21999611  transformers   \n",
       "4                                                nan   20333162  transformers   \n",
       "\n",
       "                                                soup  \n",
       "0    pytorch    jax    safetensors    wav2vec2   ...  \n",
       "1    pytorch    tf    jax    rust    safetensors ...  \n",
       "2    pytorch    tf    distilbert    token classif...  \n",
       "3    pytorch    tf    jax    tflite    rust    sa...  \n",
       "4    pytorch    tf    jax    onnx    safetensors ...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_soup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33142540-ca84-4fa5-b09d-e151896626dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CountVectorizer and create the count matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Compute the Cosine Similarity matrix based on the count_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(df_soup['soup'])\n",
    "\n",
    "#Construct a reverse map of indices and movie titles\n",
    "indices = pd.Series(df_soup.index, index=df_soup['modelId']).drop_duplicates()\n",
    "\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c46ac432-c122-464a-8fd0-2c8633547acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_cosine(df, cosine_sim, model, recommend_no):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[model]\n",
    "\n",
    "    # Get the pairwise similarity scores of all models with that models\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the models based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the X most similar movies\n",
    "    sim_scores = sim_scores[1:recommend_no+1]\n",
    "\n",
    "    # Get the movie indices\n",
    "    return_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return df.iloc[return_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6f5dbcd-92ee-46aa-a372-a7442096be30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11                            bert-base-cased\n",
      "66                         bert-large-uncased\n",
      "218     bert-large-uncased-whole-word-masking\n",
      "303                          bert-large-cased\n",
      "2091      bert-large-cased-whole-word-masking\n",
      "Name: modelId, dtype: object\n"
     ]
    }
   ],
   "source": [
    "cosine_sim_result = get_recommendations_cosine(df_soup, cosine_sim, 'bert-base-uncased', 5)\n",
    "print(cosine_sim_result['modelId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4abc9e6e-7f7f-4e12-9634-c21901bcdc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find model of index 1\n",
      "Target Model: bert-base-uncased\n",
      "5 Recommended Models:\n",
      "4376                             asafaya/bert-mini-arabic\n",
      "9562    anon-submission-mk/bert-base-macedonian-bulgar...\n",
      "3610                     jcblaise/bert-tagalog-base-cased\n",
      "1292                                             hfl/rbt3\n",
      "5972             pierreguillou/bert-base-cased-pt-lenerbr\n",
      "Name: modelId, dtype: object\n",
      "Similarity Scores: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# take jaccard similarity and compare again\n",
    "get_recommendations(df_one_hot, similarity_matrix, \"bert-base-uncased\", 5, method=\"jaccard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365e09d3-6843-4558-a9e8-147e257ab0b0",
   "metadata": {},
   "source": [
    "The results are different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e186bdbb-7b64-4066-9a05-17959e69b5ca",
   "metadata": {},
   "source": [
    "## KNN\n",
    "\n",
    "[sklearn.neighbors.NearestNeighbors — scikit-learn 1.2.2 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d9ee60c1-c7af-43c0-8419-49e192315e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "359c6e8a-eb75-4500-9e3e-73a2adc49a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_feat_cols = df_one_hot.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eb922fd7-3c55-4e3b-b8e8-1a41963811bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = knn_feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d2523629-25ce-469e-9507-ba3d122f9c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = NearestNeighbors(n_neighbors=len(df), algorithm='auto').fit(X)\n",
    "distances, indices = knn.kneighbors(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4062609d-d261-4998-8336-2f92847f1cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 2.82842712, 2.82842712,\n",
       "        2.82842712],\n",
       "       [0.        , 0.        , 0.        , ..., 2.82842712, 2.82842712,\n",
       "        2.82842712],\n",
       "       [0.        , 0.        , 0.        , ..., 2.82842712, 2.82842712,\n",
       "        2.82842712],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 2.82842712, 2.82842712,\n",
       "        2.82842712],\n",
       "       [0.        , 0.        , 0.        , ..., 2.82842712, 2.82842712,\n",
       "        2.82842712],\n",
       "       [0.        , 1.41421356, 1.41421356, ..., 2.82842712, 2.82842712,\n",
       "        2.82842712]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6c431400-0a07-4193-97e7-fd891ee23c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_knn(df, distances, indices, modelId, recommend_no):\n",
    "    if modelId in df['modelId'].values:\n",
    "        index = df[df['modelId'] == modelId].index[0]\n",
    "        print(f\"Find model of index {index}\")\n",
    "        \n",
    "    else:\n",
    "        print(f'Error: product_name \"{product_name}\" not found in dataframe.')\n",
    "\n",
    "    similar_indices = indices[index].argsort()[::-1][1:recommend_no+1]\n",
    "    similar_models = df.iloc[similar_indices]['modelId']\n",
    "    similarity_scores = 1 - distances[index][1:recommend_no+1]\n",
    "\n",
    "    print(f'Target Model: {df.iloc[index][\"modelId\"]}')\n",
    "    print(f'{recommend_no} Recommended Models:\\n{similar_models}')\n",
    "    print(f'Similarity Scores: {similarity_scores}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3bea5522-2b41-4f11-8888-642a90ee1496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find model of index 1\n",
      "Target Model: bert-base-uncased\n",
      "5 Recommended Models:\n",
      "1283                    microsoft/GODEL-v1_1-base-seq2seq\n",
      "5859                        theojolliffe/bart-cnn-science\n",
      "5857                       patrickvonplaten/wav2vec2-base\n",
      "5850    ynie/bart-large-snli_mnli_fever_anli_R1_R2_R3-nli\n",
      "5849                    sultan/BioM-ALBERT-xxlarge-SQuAD2\n",
      "Name: modelId, dtype: object\n",
      "Similarity Scores: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "get_recommendations_knn(df_mini, distances, indices, \"bert-base-uncased\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "24164ad4-7070-42af-bda2-cbc4a841f375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Product: bert-base-uncased\n",
      "5 Recommended Products:\n",
      "4330              IDEA-CCNL/Erlangshen-Ubert-110M-Chinese\n",
      "4022                        OpenMatch/cocodr-base-msmarco\n",
      "9443    redewiedergabe/bert-base-historical-german-rw-...\n",
      "3113                        uer/chinese_roberta_L-2_H-768\n",
      "226                                        klue/bert-base\n",
      "Name: modelId, dtype: object\n",
      "Similarity Scores: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "product_index = 1  # Index of product to recommend similar products for\n",
    "k = 5  # Number of similar products to recommend\n",
    "similar_indices = indices[product_index][1:k+1]  # Ignore first index, which is the product itself\n",
    "\n",
    "# 4. Return the k most similar products\n",
    "similar_products = df.iloc[similar_indices]['modelId']\n",
    "similarity_scores = 1 - distances[product_index][1:k+1]  # Convert distances to similarities\n",
    "\n",
    "print(f'Target Product: {df.iloc[product_index][\"modelId\"]}')\n",
    "print(f'{k} Recommended Products:\\n{similar_products}')\n",
    "print(f'Similarity Scores: {similarity_scores}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaac40a-f558-4eb4-b450-41def9b2a174",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "16ab32d1-ae98-4bf8-b343-904e36546426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f72f94c7-0753-4b60-9584-4bfeb85bb05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelId</th>\n",
       "      <th>pipeline_tag</th>\n",
       "      <th>architectures</th>\n",
       "      <th>model_type</th>\n",
       "      <th>library_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jonatasgrosman/wav2vec2-large-xlsr-53-english</td>\n",
       "      <td>automatic-speech-recognition</td>\n",
       "      <td>'Wav2Vec2ForCTC'</td>\n",
       "      <td>wav2vec2</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>'BertForMaskedLM'</td>\n",
       "      <td>bert</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Davlan/distilbert-base-multilingual-cased-ner-hrl</td>\n",
       "      <td>token-classification</td>\n",
       "      <td>'DistilBertForTokenClassification'</td>\n",
       "      <td>distilbert</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>'GPT2LMHeadModel'</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>'XLMRobertaForMaskedLM'</td>\n",
       "      <td>xlm-roberta</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>ans/vaccinating-covid-tweets</td>\n",
       "      <td>text-classification</td>\n",
       "      <td>'RobertaForSequenceClassification'</td>\n",
       "      <td>roberta</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>bakrianoo/sinai-voice-ar-stt</td>\n",
       "      <td>automatic-speech-recognition</td>\n",
       "      <td>'Wav2Vec2ForCTC'</td>\n",
       "      <td>wav2vec2</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>danyaljj/gpt2_question_generation_given_paragr...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>'GPT2LMHeadModel'</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>dkleczek/Polish-Hate-Speech-Detection-Herbert-...</td>\n",
       "      <td>text-classification</td>\n",
       "      <td>'BertForSequenceClassification'</td>\n",
       "      <td>bert</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>doyoungkim/bert-base-uncased-finetuned-sst2</td>\n",
       "      <td>text-classification</td>\n",
       "      <td>'MyBertForSequenceClassification'</td>\n",
       "      <td>bert</td>\n",
       "      <td>transformers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                modelId  \\\n",
       "0         jonatasgrosman/wav2vec2-large-xlsr-53-english   \n",
       "1                                     bert-base-uncased   \n",
       "2     Davlan/distilbert-base-multilingual-cased-ner-hrl   \n",
       "3                                                  gpt2   \n",
       "4                                      xlm-roberta-base   \n",
       "...                                                 ...   \n",
       "9995                       ans/vaccinating-covid-tweets   \n",
       "9996                       bakrianoo/sinai-voice-ar-stt   \n",
       "9997  danyaljj/gpt2_question_generation_given_paragr...   \n",
       "9998  dkleczek/Polish-Hate-Speech-Detection-Herbert-...   \n",
       "9999        doyoungkim/bert-base-uncased-finetuned-sst2   \n",
       "\n",
       "                      pipeline_tag                       architectures  \\\n",
       "0     automatic-speech-recognition                    'Wav2Vec2ForCTC'   \n",
       "1                        fill-mask                   'BertForMaskedLM'   \n",
       "2             token-classification  'DistilBertForTokenClassification'   \n",
       "3                  text-generation                   'GPT2LMHeadModel'   \n",
       "4                        fill-mask             'XLMRobertaForMaskedLM'   \n",
       "...                            ...                                 ...   \n",
       "9995           text-classification  'RobertaForSequenceClassification'   \n",
       "9996  automatic-speech-recognition                    'Wav2Vec2ForCTC'   \n",
       "9997               text-generation                   'GPT2LMHeadModel'   \n",
       "9998           text-classification     'BertForSequenceClassification'   \n",
       "9999           text-classification   'MyBertForSequenceClassification'   \n",
       "\n",
       "       model_type  library_name  \n",
       "0        wav2vec2  transformers  \n",
       "1            bert  transformers  \n",
       "2      distilbert  transformers  \n",
       "3            gpt2  transformers  \n",
       "4     xlm-roberta  transformers  \n",
       "...           ...           ...  \n",
       "9995      roberta  transformers  \n",
       "9996     wav2vec2  transformers  \n",
       "9997         gpt2  transformers  \n",
       "9998         bert  transformers  \n",
       "9999         bert  transformers  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ed650e5d-91f2-4a77-a130-4559b753fd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline_tag_audio-classification</th>\n",
       "      <th>pipeline_tag_audio-to-audio</th>\n",
       "      <th>pipeline_tag_automatic-speech-recognition</th>\n",
       "      <th>pipeline_tag_conversational</th>\n",
       "      <th>pipeline_tag_depth-estimation</th>\n",
       "      <th>pipeline_tag_document-question-answering</th>\n",
       "      <th>pipeline_tag_feature-extraction</th>\n",
       "      <th>pipeline_tag_fill-mask</th>\n",
       "      <th>pipeline_tag_graph-ml</th>\n",
       "      <th>pipeline_tag_image-classification</th>\n",
       "      <th>...</th>\n",
       "      <th>library_name_span_marker</th>\n",
       "      <th>library_name_speechbrain</th>\n",
       "      <th>library_name_stable-baselines3</th>\n",
       "      <th>library_name_stable-diffusion</th>\n",
       "      <th>library_name_stanza</th>\n",
       "      <th>library_name_timm</th>\n",
       "      <th>library_name_transformers</th>\n",
       "      <th>library_name_txtai</th>\n",
       "      <th>library_name_ultralytics</th>\n",
       "      <th>library_name_yolov5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1007 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pipeline_tag_audio-classification  pipeline_tag_audio-to-audio  \\\n",
       "0                                     0                            0   \n",
       "1                                     0                            0   \n",
       "2                                     0                            0   \n",
       "3                                     0                            0   \n",
       "4                                     0                            0   \n",
       "...                                 ...                          ...   \n",
       "9995                                  0                            0   \n",
       "9996                                  0                            0   \n",
       "9997                                  0                            0   \n",
       "9998                                  0                            0   \n",
       "9999                                  0                            0   \n",
       "\n",
       "      pipeline_tag_automatic-speech-recognition  pipeline_tag_conversational  \\\n",
       "0                                             1                            0   \n",
       "1                                             0                            0   \n",
       "2                                             0                            0   \n",
       "3                                             0                            0   \n",
       "4                                             0                            0   \n",
       "...                                         ...                          ...   \n",
       "9995                                          0                            0   \n",
       "9996                                          1                            0   \n",
       "9997                                          0                            0   \n",
       "9998                                          0                            0   \n",
       "9999                                          0                            0   \n",
       "\n",
       "      pipeline_tag_depth-estimation  pipeline_tag_document-question-answering  \\\n",
       "0                                 0                                         0   \n",
       "1                                 0                                         0   \n",
       "2                                 0                                         0   \n",
       "3                                 0                                         0   \n",
       "4                                 0                                         0   \n",
       "...                             ...                                       ...   \n",
       "9995                              0                                         0   \n",
       "9996                              0                                         0   \n",
       "9997                              0                                         0   \n",
       "9998                              0                                         0   \n",
       "9999                              0                                         0   \n",
       "\n",
       "      pipeline_tag_feature-extraction  pipeline_tag_fill-mask  \\\n",
       "0                                   0                       0   \n",
       "1                                   0                       1   \n",
       "2                                   0                       0   \n",
       "3                                   0                       0   \n",
       "4                                   0                       1   \n",
       "...                               ...                     ...   \n",
       "9995                                0                       0   \n",
       "9996                                0                       0   \n",
       "9997                                0                       0   \n",
       "9998                                0                       0   \n",
       "9999                                0                       0   \n",
       "\n",
       "      pipeline_tag_graph-ml  pipeline_tag_image-classification  ...  \\\n",
       "0                         0                                  0  ...   \n",
       "1                         0                                  0  ...   \n",
       "2                         0                                  0  ...   \n",
       "3                         0                                  0  ...   \n",
       "4                         0                                  0  ...   \n",
       "...                     ...                                ...  ...   \n",
       "9995                      0                                  0  ...   \n",
       "9996                      0                                  0  ...   \n",
       "9997                      0                                  0  ...   \n",
       "9998                      0                                  0  ...   \n",
       "9999                      0                                  0  ...   \n",
       "\n",
       "      library_name_span_marker  library_name_speechbrain  \\\n",
       "0                            0                         0   \n",
       "1                            0                         0   \n",
       "2                            0                         0   \n",
       "3                            0                         0   \n",
       "4                            0                         0   \n",
       "...                        ...                       ...   \n",
       "9995                         0                         0   \n",
       "9996                         0                         0   \n",
       "9997                         0                         0   \n",
       "9998                         0                         0   \n",
       "9999                         0                         0   \n",
       "\n",
       "      library_name_stable-baselines3  library_name_stable-diffusion  \\\n",
       "0                                  0                              0   \n",
       "1                                  0                              0   \n",
       "2                                  0                              0   \n",
       "3                                  0                              0   \n",
       "4                                  0                              0   \n",
       "...                              ...                            ...   \n",
       "9995                               0                              0   \n",
       "9996                               0                              0   \n",
       "9997                               0                              0   \n",
       "9998                               0                              0   \n",
       "9999                               0                              0   \n",
       "\n",
       "      library_name_stanza  library_name_timm  library_name_transformers  \\\n",
       "0                       0                  0                          1   \n",
       "1                       0                  0                          1   \n",
       "2                       0                  0                          1   \n",
       "3                       0                  0                          1   \n",
       "4                       0                  0                          1   \n",
       "...                   ...                ...                        ...   \n",
       "9995                    0                  0                          1   \n",
       "9996                    0                  0                          1   \n",
       "9997                    0                  0                          1   \n",
       "9998                    0                  0                          1   \n",
       "9999                    0                  0                          1   \n",
       "\n",
       "      library_name_txtai  library_name_ultralytics  library_name_yolov5  \n",
       "0                      0                         0                    0  \n",
       "1                      0                         0                    0  \n",
       "2                      0                         0                    0  \n",
       "3                      0                         0                    0  \n",
       "4                      0                         0                    0  \n",
       "...                  ...                       ...                  ...  \n",
       "9995                   0                         0                    0  \n",
       "9996                   0                         0                    0  \n",
       "9997                   0                         0                    0  \n",
       "9998                   0                         0                    0  \n",
       "9999                   0                         0                    0  \n",
       "\n",
       "[10000 rows x 1007 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oh_feats = pd.get_dummies(df_mini.iloc[:, 1:])\n",
    "df_oh_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dae5dc4b-55f9-4d52-92d7-5f29b3f0e50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/mini/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=10)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=10)\n",
    "kmeans.fit(df_oh_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "05b1473d-fc57-489f-b649-5dc8742ffb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelId</th>\n",
       "      <th>pipeline_tag_audio-classification</th>\n",
       "      <th>pipeline_tag_audio-to-audio</th>\n",
       "      <th>pipeline_tag_automatic-speech-recognition</th>\n",
       "      <th>pipeline_tag_conversational</th>\n",
       "      <th>pipeline_tag_depth-estimation</th>\n",
       "      <th>pipeline_tag_document-question-answering</th>\n",
       "      <th>pipeline_tag_feature-extraction</th>\n",
       "      <th>pipeline_tag_fill-mask</th>\n",
       "      <th>pipeline_tag_graph-ml</th>\n",
       "      <th>...</th>\n",
       "      <th>library_name_span_marker</th>\n",
       "      <th>library_name_speechbrain</th>\n",
       "      <th>library_name_stable-baselines3</th>\n",
       "      <th>library_name_stable-diffusion</th>\n",
       "      <th>library_name_stanza</th>\n",
       "      <th>library_name_timm</th>\n",
       "      <th>library_name_transformers</th>\n",
       "      <th>library_name_txtai</th>\n",
       "      <th>library_name_ultralytics</th>\n",
       "      <th>library_name_yolov5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jonatasgrosman/wav2vec2-large-xlsr-53-english</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Davlan/distilbert-base-multilingual-cased-ner-hrl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>ans/vaccinating-covid-tweets</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>bakrianoo/sinai-voice-ar-stt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>danyaljj/gpt2_question_generation_given_paragr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>dkleczek/Polish-Hate-Speech-Detection-Herbert-...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>doyoungkim/bert-base-uncased-finetuned-sst2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                modelId  \\\n",
       "0         jonatasgrosman/wav2vec2-large-xlsr-53-english   \n",
       "1                                     bert-base-uncased   \n",
       "2     Davlan/distilbert-base-multilingual-cased-ner-hrl   \n",
       "3                                                  gpt2   \n",
       "4                                      xlm-roberta-base   \n",
       "...                                                 ...   \n",
       "9995                       ans/vaccinating-covid-tweets   \n",
       "9996                       bakrianoo/sinai-voice-ar-stt   \n",
       "9997  danyaljj/gpt2_question_generation_given_paragr...   \n",
       "9998  dkleczek/Polish-Hate-Speech-Detection-Herbert-...   \n",
       "9999        doyoungkim/bert-base-uncased-finetuned-sst2   \n",
       "\n",
       "      pipeline_tag_audio-classification  pipeline_tag_audio-to-audio  \\\n",
       "0                                     0                            0   \n",
       "1                                     0                            0   \n",
       "2                                     0                            0   \n",
       "3                                     0                            0   \n",
       "4                                     0                            0   \n",
       "...                                 ...                          ...   \n",
       "9995                                  0                            0   \n",
       "9996                                  0                            0   \n",
       "9997                                  0                            0   \n",
       "9998                                  0                            0   \n",
       "9999                                  0                            0   \n",
       "\n",
       "      pipeline_tag_automatic-speech-recognition  pipeline_tag_conversational  \\\n",
       "0                                             1                            0   \n",
       "1                                             0                            0   \n",
       "2                                             0                            0   \n",
       "3                                             0                            0   \n",
       "4                                             0                            0   \n",
       "...                                         ...                          ...   \n",
       "9995                                          0                            0   \n",
       "9996                                          1                            0   \n",
       "9997                                          0                            0   \n",
       "9998                                          0                            0   \n",
       "9999                                          0                            0   \n",
       "\n",
       "      pipeline_tag_depth-estimation  pipeline_tag_document-question-answering  \\\n",
       "0                                 0                                         0   \n",
       "1                                 0                                         0   \n",
       "2                                 0                                         0   \n",
       "3                                 0                                         0   \n",
       "4                                 0                                         0   \n",
       "...                             ...                                       ...   \n",
       "9995                              0                                         0   \n",
       "9996                              0                                         0   \n",
       "9997                              0                                         0   \n",
       "9998                              0                                         0   \n",
       "9999                              0                                         0   \n",
       "\n",
       "      pipeline_tag_feature-extraction  pipeline_tag_fill-mask  \\\n",
       "0                                   0                       0   \n",
       "1                                   0                       1   \n",
       "2                                   0                       0   \n",
       "3                                   0                       0   \n",
       "4                                   0                       1   \n",
       "...                               ...                     ...   \n",
       "9995                                0                       0   \n",
       "9996                                0                       0   \n",
       "9997                                0                       0   \n",
       "9998                                0                       0   \n",
       "9999                                0                       0   \n",
       "\n",
       "      pipeline_tag_graph-ml  ...  library_name_span_marker  \\\n",
       "0                         0  ...                         0   \n",
       "1                         0  ...                         0   \n",
       "2                         0  ...                         0   \n",
       "3                         0  ...                         0   \n",
       "4                         0  ...                         0   \n",
       "...                     ...  ...                       ...   \n",
       "9995                      0  ...                         0   \n",
       "9996                      0  ...                         0   \n",
       "9997                      0  ...                         0   \n",
       "9998                      0  ...                         0   \n",
       "9999                      0  ...                         0   \n",
       "\n",
       "      library_name_speechbrain  library_name_stable-baselines3  \\\n",
       "0                            0                               0   \n",
       "1                            0                               0   \n",
       "2                            0                               0   \n",
       "3                            0                               0   \n",
       "4                            0                               0   \n",
       "...                        ...                             ...   \n",
       "9995                         0                               0   \n",
       "9996                         0                               0   \n",
       "9997                         0                               0   \n",
       "9998                         0                               0   \n",
       "9999                         0                               0   \n",
       "\n",
       "      library_name_stable-diffusion  library_name_stanza  library_name_timm  \\\n",
       "0                                 0                    0                  0   \n",
       "1                                 0                    0                  0   \n",
       "2                                 0                    0                  0   \n",
       "3                                 0                    0                  0   \n",
       "4                                 0                    0                  0   \n",
       "...                             ...                  ...                ...   \n",
       "9995                              0                    0                  0   \n",
       "9996                              0                    0                  0   \n",
       "9997                              0                    0                  0   \n",
       "9998                              0                    0                  0   \n",
       "9999                              0                    0                  0   \n",
       "\n",
       "      library_name_transformers  library_name_txtai  library_name_ultralytics  \\\n",
       "0                             1                   0                         0   \n",
       "1                             1                   0                         0   \n",
       "2                             1                   0                         0   \n",
       "3                             1                   0                         0   \n",
       "4                             1                   0                         0   \n",
       "...                         ...                 ...                       ...   \n",
       "9995                          1                   0                         0   \n",
       "9996                          1                   0                         0   \n",
       "9997                          1                   0                         0   \n",
       "9998                          1                   0                         0   \n",
       "9999                          1                   0                         0   \n",
       "\n",
       "      library_name_yolov5  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "...                   ...  \n",
       "9995                    0  \n",
       "9996                    0  \n",
       "9997                    0  \n",
       "9998                    0  \n",
       "9999                    0  \n",
       "\n",
       "[10000 rows x 1008 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ec9aff52-5ff6-4982-9c3b-b0c819e7ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_kmeans(df, df_encoded, model, modelId, recommend_no):\n",
    "    # Encode the input product's features\n",
    "    product_encoded = df[df['modelId'] == modelId].drop('modelId', axis=1)\n",
    "    # print(product_encoded)\n",
    "    # Predict the cluster of the input product\n",
    "    cluster = kmeans.predict(product_encoded)\n",
    "    \n",
    "    # Get indices of all products in the same cluster as the input product\n",
    "    indices = df_encoded[kmeans.labels_ == cluster[0]].index\n",
    "    \n",
    "    # Compute similarity scores between the input product and all products in the same cluster\n",
    "    similarity_scores = cosine_similarity(product_encoded, df_encoded.loc[indices])[0]\n",
    "    \n",
    "    # Sort the products by similarity score and return top k recommendations\n",
    "    similar_indices = similarity_scores.argsort()[::-1][1:recommend_no+1]\n",
    "    similar_products = df.iloc[indices[similar_indices]]['modelId']\n",
    "    \n",
    "    return similar_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "172ce06b-c7b2-47c4-9cea-1e2341d88e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4349    KBLab/bert-base-swedish-cased-new\n",
       "4035                  SI2M-Lab/DarijaBERT\n",
       "4096    alexanderfalk/danbert-small-cased\n",
       "4098               avichr/Legal-heBERT_ft\n",
       "4102      recobo/agriculture-bert-uncased\n",
       "Name: modelId, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_products_kmeans = get_recommendations_kmeans(df_one_hot, df_oh_feats, kmeans, \"bert-base-uncased\", 5)\n",
    "similar_products_kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384ca9a0-f05e-48f5-ba18-2daedd700c76",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering (#todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ff0648cd-e7a8-4b36-b9e4-1f12d3519af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "365a51b5-57f1-4299-82fa-58bbaedc0e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_hierarchical(df, df_encoded, modelId, recommend_no):\n",
    "    # Encode the input product's features\n",
    "    product_encoded = df[df['modelId'] == modelId].drop('modelId', axis=1)\n",
    "    \n",
    "    # Compute pairwise cosine similarity between all products\n",
    "    similarity_matrix = cosine_similarity(df_encoded)\n",
    "    \n",
    "    # Perform hierarchical clustering on the pairwise similarity matrix\n",
    "    linkage_matrix = linkage(similarity_matrix, method='ward')\n",
    "    \n",
    "    # Determine the cluster containing the input product\n",
    "    cluster = fcluster(linkage_matrix, t=0.5, criterion='distance', depth=10)\n",
    "    return cluster\n",
    "\n",
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3e78024e-fafa-44c4-98ca-11faa8dd23cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([471, 148, 523, ..., 242, 147, 187], dtype=int32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = get_recommendations_hierarchical(df_one_hot, df_oh_feats, \"bert-base-uncased\", 5)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9586cb75-3e4f-4e27-a608-028f9965ea97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91bcdb1-0a83-4e29-827a-93bfcd75d384",
   "metadata": {},
   "source": [
    "Aborted for now as it takes very long to run\n",
    "\n",
    "Note that hierarchical clustering can be computationally expensive for large datasets, so it may not be the best choice for very large product catalogs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6989d8e5-24e8-4e52-ad5b-2c4e4e73dc13",
   "metadata": {},
   "source": [
    "## DBSCAN (#todo)\n",
    "\n",
    "[Movie Recommendation System (DBSCAN) | Kaggle](https://www.kaggle.com/code/olyapotemkina/movie-recommendation-system-dbscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e256fe81-dce3-45a3-8f9a-c9c8cd59c2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "34938654-5e60-48f6-82f8-10ed9d0f3a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(df_oh_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c846eed1-81fc-4abd-86d6-462c9fbc012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.5, min_samples=2, metric=\"precomputed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3f3c3058-b5c0-4a55-9dc8-21cc4cda15e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = dbscan.fit_predict(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c8d899af-53be-4cb3-b262-f1fdbb178214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_oh_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "63580125-1947-4b6b-b2f3-ea2a47d1dc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_labels.size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
